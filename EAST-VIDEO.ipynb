{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import PIL\n",
    "import IPython\n",
    "from IPython.display import clear_output,display\n",
    "import pytesseract\n",
    "#Time Lib\n",
    "import datetime\n",
    "import pymysql\n",
    "\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO\n",
    "    from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x120350a20>\n"
     ]
    }
   ],
   "source": [
    "#Connect to SQL\n",
    "db = pymysql.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd=\"root\",\n",
    "  db=\"test_connector\"  \n",
    ")\n",
    "cursor = db.cursor()\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE This method instaed of cv2.imageShow\n",
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(a)\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argvideo = ''\n",
    "argseast = 'frozen_east_text_detection.pb'\n",
    "args_min_confid = 0.70\n",
    "# multiply\n",
    "pi = np.pi\n",
    "argspad = 1/pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(scores, geometry):\n",
    "    # grab the number of rows and columns from the scores volume, then\n",
    "    # initialize our set of bounding box rectangles and corresponding\n",
    "    # confidence scores\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities), followed by the\n",
    "        # geometrical data used to derive potential bounding box\n",
    "        # coordinates that surround text\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "            # if our score does not have sufficient probability,\n",
    "            # ignore it\n",
    "            if scoresData[x] < args_min_confid:\n",
    "                continue\n",
    "\n",
    "            # compute the offset factor as our resulting feature\n",
    "            # maps will be 4x smaller than the input image\n",
    "            (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "            # extract the rotation angle for the prediction and\n",
    "            # then compute the sin and cosine\n",
    "            angle = anglesData[x]\n",
    "            cos = np.cos(angle)\n",
    "            sin = np.sin(angle)\n",
    "\n",
    "            # use the geometry volume to derive the width and height\n",
    "            # of the bounding box\n",
    "            h = xData0[x] + xData2[x]\n",
    "            w = xData1[x] + xData3[x]\n",
    "\n",
    "            # compute both the starting and ending (x, y)-coordinates\n",
    "            # for the text prediction bounding box\n",
    "            endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "            endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "            startX = int(endX - w)\n",
    "            startY = int(endY - h)\n",
    "\n",
    "            # add the bounding box coordinates and probability score\n",
    "            # to our respective lists\n",
    "            rects.append((startX, startY, endX, endY))\n",
    "            confidences.append(scoresData[x])\n",
    "\n",
    "    # return a tuple of the bounding boxes and associated confidences\n",
    "    return (rects, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n"
     ]
    }
   ],
   "source": [
    "# second can be used to derive the bounding box coordinates of text\n",
    "layerNames = [\"feature_fusion/Conv_7/Sigmoid\",\"feature_fusion/concat_3\"]\n",
    "\n",
    "# load the pre-trained EAST text detector\n",
    "print(\"[INFO] loading EAST text detector...\")\n",
    "net = cv2.dnn.readNet(argseast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import IPython\n",
    "from IPython.display import display,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tesseract_read_roi(roi):\n",
    "    path_ = 'images/snapshot/';pathArray=[];txtArray=[];remark=[];\n",
    "    if roi == []: \n",
    "        display('');\n",
    "    else :    \n",
    "        length = len(roi)-1;\n",
    "        while length >= 0:\n",
    "            img = roi[length]\n",
    "\n",
    "            # process img for ocr : resizeX2 -> Gray Scale -> mode treshold\n",
    "            img = cv2.resize(img,None,fx=2,fy=2)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            # Threshold\n",
    "            # adaptive gaussian threshold\n",
    "        #     img_agt = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,9,2)\n",
    "            # adaptive mean threshold\n",
    "        #     img_amt = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,9,2)\n",
    "            # OTSU threshold\n",
    "            ret_otsu,img_otsu = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            # Otsu's thresholding after Gaussian filtering\n",
    "        #     blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "        #     ret_otsug,img_otsug = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "             # in order to apply Tesseract v4 to OCR text we must supply\n",
    "            # (1) a language, (2) an OEM flag of 4, indicating that the we\n",
    "            # wish to use the LSTM neural net model for OCR, and finally\n",
    "            # (3) an OEM value, in this case, 7 which implies that we are\n",
    "            # treating the ROI as a single line of text\n",
    "\n",
    "            config = (\"-l eng --oem 1 --psm 7\")\n",
    "            text = pytesseract.image_to_string(img_otsu, config=config)\n",
    "            \n",
    "            # display\n",
    "            showarray(img_otsu);\n",
    "            print(text);\n",
    "            \n",
    "            # Write into database\n",
    "            ts = datetime.datetime.now().timestamp()\n",
    "            ts = str(int(ts))\n",
    "            path = path_+ts+'.jpg'\n",
    "            cv2.imwrite(path,img_otsu)\n",
    "            pathArray.append(path)\n",
    "            path = path_\n",
    "            \n",
    "            #text\n",
    "            txtArray.append(text)\n",
    "            \n",
    "            length -= 1\n",
    "            \n",
    "        #end while loop\n",
    "        timestamp = datetime.datetime.now();\n",
    "        pathlist = pathArray;\n",
    "        txtlist = txtArray;\n",
    "        remark = '';\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT into testRecord (Timestamp, ImgPath, Text, Remark) values(%s,%r,%r,%s)\n",
    "            \"\"\",(timestamp,pathlist,txtlist,remark))\n",
    "#         db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_counter_snap(asyncState):\n",
    "    while 1:\n",
    "        await asyncio.sleep(1);\n",
    "        asyncState.counter += 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_run_video(asyncState):\n",
    "    try:    \n",
    "        while 1:\n",
    "            await asyncio.sleep(0.00000000000000001);\n",
    "            clear_output(wait=True);\n",
    "            roi = [];\n",
    "            # grab the current frame, then handle if we are using a\n",
    "            # VideoStream or VideoCapture object\n",
    "            vs = asyncState.vs\n",
    "            frame = vs.read()\n",
    "\n",
    "            # check to see if we have reached the end of the stream\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            # resize the frame, maintaining the aspect ratio\n",
    "            frame = imutils.resize(frame, width=1000)\n",
    "            orig = frame.copy();roi_crop = frame.copy();\n",
    "            orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # if our frame dimensions are None, we still need to compute the\n",
    "            # ratio of old frame dimensions to new frame dimensions\n",
    "            if asyncState.W is None or asyncState.H is None:\n",
    "                (asyncState.H, asyncState.W) = frame.shape[:2]\n",
    "                asyncState.rW = asyncState.W / float(asyncState.newW)\n",
    "                asyncState.rH = asyncState.H / float(asyncState.newH)\n",
    "\n",
    "            # resize the frame, this time ignoring aspect ratio\n",
    "            frame = cv2.resize(frame, (asyncState.newW, asyncState.newH))\n",
    "\n",
    "            # construct a blob from the frame and then perform a forward pass\n",
    "            # of the model to obtain the two output layer sets\n",
    "            blob = cv2.dnn.blobFromImage(frame, 1.0, (asyncState.newW, asyncState.newH),(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "            # decode the predictions, then  apply non-maxima suppression to\n",
    "            # suppress weak, overlapping bounding boxes\n",
    "            (rects, confidences) = decode_predictions(scores, geometry)\n",
    "            boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "            \n",
    "            \n",
    "            # loop over the bounding boxes\n",
    "            for (startX, startY, endX, endY) in boxes:\n",
    "                # scale the bounding box coordinates based on the respective\n",
    "                # ratios\n",
    "                # in order to obtain a better OCR of the text we can potentially\n",
    "                # apply a bit of padding surrounding the bounding box -- here we\n",
    "                # are computing the deltas in both the x and y directions\n",
    "                dX = int((endX - startX) * argspad)\n",
    "                dY = int((endY - startY) * argspad)\n",
    "                startX = int((startX * asyncState.rW)-dX/5)\n",
    "                startY = int((startY * asyncState.rH)-dY/5)\n",
    "                endX = int((endX * asyncState.rW)+dX/5)\n",
    "                endY = int((endY * asyncState.rH)+dY/5)\n",
    "                tmp = roi_crop[startY:endY, startX:endX] \n",
    "                roi.append(tmp);\n",
    "                # draw the bounding box on the frame\n",
    "                cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "            # update the FPS counter\n",
    "            fps = asyncState.fps\n",
    "            fps.update()\n",
    "\n",
    "            # show the output frame\n",
    "            showarray(orig);\n",
    "            display(asyncState.counter);\n",
    "            if asyncState.counter >= 5:\n",
    "                asyncState.counter=0;\n",
    "                asyncState.roi = roi;\n",
    "                tesseract_read_roi(asyncState.roi);\n",
    "                continue;\n",
    "            # Display the frame until new frame is available\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "            print('\\n\\nKeyboard exception received. Exiting.')    \n",
    "            # stop the timer and display FPS information\n",
    "            fps.stop();vs.stop()\n",
    "            print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "            print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Setup an object to track the state\n",
    "    asyncState = type('', (), {})()\n",
    "    asyncState.counter = 0;\n",
    "    asyncState.marker = '';\n",
    "    asyncState.roi = []; asyncState.magik_num = 1/np.pi;\n",
    "    \n",
    "    # if a video path was not supplied, grab the reference to the web cam\n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    asyncState.vs = VideoStream(src=0).start()\n",
    "\n",
    "    # start the FPS throughput estimator\n",
    "    asyncState.fps = FPS().start()\n",
    "    # initialize the original frame dimensions, new frame dimensions,\n",
    "    # and ratio between the dimensions\n",
    "    asyncState.argsw = 320; asyncState.argsh = 320\n",
    "    (asyncState.W, asyncState.H) = (None, None)\n",
    "    (asyncState.newW, asyncState.newH) = (asyncState.argsw, asyncState.argsh)\n",
    "    (asyncState.rW, asyncState.rH) = (None, None)\n",
    "\n",
    "    await asyncio.gather(async_counter_snap(asyncState),async_run_video(asyncState))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_UnixSelectorEventLoop running=False closed=False debug=False>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop = asyncio.new_event_loop()\n",
    "asyncio.set_event_loop(loop)\n",
    "asyncio.get_event_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Keyboard exception received. Exiting.\n",
      "[INFO] elasped time: 22.83\n",
      "[INFO] approx. FPS: 2.54\n",
      "close loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    future = loop.create_task(main())\n",
    "    loop.run_until_complete(future)\n",
    "except:\n",
    "    pass\n",
    "finally:\n",
    "    print('close loop')\n",
    "    loop.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_UnixSelectorEventLoop running=False closed=True debug=False>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, datetime.datetime(2019, 3, 28, 14, 36, 43), 'Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(2, datetime.datetime(2019, 3, 28, 14, 42, 12), 'Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(3, datetime.datetime(2019, 3, 28, 14, 42, 44), 'Desktop/python/jupyter/txt-e.jpg,Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(4, datetime.datetime(2019, 3, 28, 8, 22, 53), \"('Desktop/python/jupyter/txt-x.jpg','Desktop/python/jupyter/txt-y.jpg','Desktop/python/jupyter/txt-z.jpg')\", \"('intania90','intania91','intania92')\", 'test_pathlist')\n",
      "(11, datetime.datetime(2019, 3, 28, 16, 54, 50), \"'images/snapshot/1553766890.jpg'\", \"'txtArray'\", '[]')\n",
      "(12, datetime.datetime(2019, 3, 28, 16, 54, 50), \"('images/snapshot/1553766890.jpg','images/snapshot/1553766890.jpg')\", \"('txtArray','txtArray')\", '[]')\n",
      "(13, datetime.datetime(2019, 3, 28, 17, 9, 31), \"('images/snapshot/1553767770.jpg')\", \"('ein cued')\", '')\n",
      "(14, datetime.datetime(2019, 3, 28, 17, 9, 37), \"('images/snapshot/1553767777.jpg')\", \"('CULCURE')\", '')\n",
      "(15, datetime.datetime(2019, 3, 28, 17, 9, 44), \"('images/snapshot/1553767783.jpg')\", \"('')\", '')\n",
      "(18, datetime.datetime(2019, 3, 28, 17, 13, 36), \"('images/snapshot/1553768014.jpg','images/snapshot/1553768015.jpg','images/snapshot/1553768015.jpg')\", \"('','CHIT Lee','=2Mn Ue')\", '')\n",
      "(19, datetime.datetime(2019, 3, 28, 17, 13, 42), \"('images/snapshot/1553768021.jpg','images/snapshot/1553768021.jpg','images/snapshot/1553768021.jpg')\", \"('','CULCURE','FURNn TURE')\", '')\n",
      "(20, datetime.datetime(2019, 3, 28, 17, 13, 48), \"('images/snapshot/1553768027.jpg','images/snapshot/1553768027.jpg','images/snapshot/1553768027.jpg')\", \"('y= oe','m ti bates','Sted eral TE tS')\", '')\n"
     ]
    }
   ],
   "source": [
    "#Show Records\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM testRecord\n",
    "    \"\"\")\n",
    "\n",
    "for x in cursor:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/snapshot/1553765174.jpg'\n",
    "image = cv2.imread(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = datetime.datetime.now().timestamp()\n",
    "ts = str(int(ts))\n",
    "path_ = 'images/snapshot/'\n",
    "pathl = path_+ts+'.jpg'\n",
    "cv2.imwrite(path,image)\n",
    "# pathArray.append(path)\n",
    "# #text\n",
    "# print(text);\n",
    "# txtArray.append(text)\n",
    "# length -= 1\n",
    "\n",
    "#end while loop\n",
    "timestamp = datetime.datetime.now();\n",
    "pathlist = pathl;\n",
    "txtlist = 'txtArray';\n",
    "remark = '[]';\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT into testRecord (Timestamp, ImgPath, Text, Remark) values(%s,%r,%r,%s)\n",
    "    \"\"\",(timestamp,pathlist,txtlist,remark))\n",
    "# db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now();\n",
    "pathArray = []; txtArray = []\n",
    "pathArray.append(pathl);txtArray.append(txtlist);\n",
    "pathArray.append(pathl);txtArray.append(txtlist);\n",
    "remark = '[]';\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT into testRecord (Timestamp, ImgPath, Text, Remark) values(%s,%r,%r,%s)\n",
    "    \"\"\",(timestamp,pathArray,txtArray,remark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, datetime.datetime(2019, 3, 28, 14, 36, 43), 'Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(2, datetime.datetime(2019, 3, 28, 14, 42, 12), 'Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(3, datetime.datetime(2019, 3, 28, 14, 42, 44), 'Desktop/python/jupyter/txt-e.jpg,Desktop/python/jupyter/txt-e.jpg', 'intania93', 'test4')\n",
      "(4, datetime.datetime(2019, 3, 28, 8, 22, 53), \"('Desktop/python/jupyter/txt-x.jpg','Desktop/python/jupyter/txt-y.jpg','Desktop/python/jupyter/txt-z.jpg')\", \"('intania90','intania91','intania92')\", 'test_pathlist')\n",
      "(11, datetime.datetime(2019, 3, 28, 16, 54, 50), \"'images/snapshot/1553766890.jpg'\", \"'txtArray'\", '[]')\n",
      "(12, datetime.datetime(2019, 3, 28, 16, 54, 50), \"('images/snapshot/1553766890.jpg','images/snapshot/1553766890.jpg')\", \"('txtArray','txtArray')\", '[]')\n"
     ]
    }
   ],
   "source": [
    "#Show Records\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    SELECT * FROM testRecord\n",
    "    \"\"\")\n",
    "\n",
    "for x in cursor:\n",
    "  print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
